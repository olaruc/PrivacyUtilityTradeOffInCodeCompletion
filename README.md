# Privacy-Utility-Trade-off-in-Code-Completion

## Analysis of the trade-off
The resulting scatter plot shows a distinct and understandable connection between code completion utility and privacy.  As may be predicted, prompts without any obfuscation have the lowest privacy ratings because they are exactly the same as the original HumanEval inputs.  Additionally, these locations get the maximum utility values, suggesting that clean, fully expressive code optimizes the model's performance.  The privacy score somewhat rises when light obfuscation is applied, such as straightforward variable renaming or little surface-level changes.  It's interesting to note that the utility values for somewhat disguised prompts still cluster close to those of the original inputs, indicating a rather minor commensurate drop in usefulness.  This implies that while maintaining a high degree of model performance, modest, structure-preserving obfuscation can provide enhanced privacy.

In contrast, extensively obfuscated prompts result in a significant improvement in privacy, with scores concentrated toward the top of the scale.  This illustrates that aggressive transformations, such as placeholder substitution and comment stripping, are successful in preventing direct reconstruction or statistical leakage of the source code.  However, these increases are accompanied by a considerable decrease in utility.  When a large amount of semantic or structural information is missing, the model fails to create proper completions, resulting in much lower ROUGE scores throughout this group.  Taken together, the findings demonstrate a well-known privacy-utility trade-off: more obfuscation leads in increased privacy but at the expense of reduced model effectiveness.Light obfuscation appears to be a promising middle ground, delivering significant privacy benefits while retaining most of the model's capacity to generate high-quality completions.


